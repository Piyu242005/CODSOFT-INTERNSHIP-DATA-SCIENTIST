{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ’³ Credit Card Fraud Detection\n",
                "\n",
                "---\n",
                "\n",
                "**Author:** Piyush Ramteke  \n",
                "**Program:** CodSoft Data Science Internship  \n",
                "**Task:** Task 3 - Credit Card Fraud Detection\n",
                "\n",
                "---\n",
                "\n",
                "## ğŸš¨ Problem Statement\n",
                "\n",
                "Credit card fraud causes billions of dollars in losses every year. As digital payments grow, so does fraudulent activity. The challenge is to **automatically detect fraudulent transactions** among hundreds of thousands of legitimate ones.\n",
                "\n",
                "This is a **binary classification** problem:\n",
                "- **Class 0** ğŸŸ¢ â†’ Genuine transaction\n",
                "- **Class 1** ğŸ”´ â†’ Fraudulent transaction\n",
                "\n",
                "The key difficulty is **class imbalance** â€” frauds make up less than 0.2% of all transactions. A naive model that predicts everything as \"genuine\" would get 99.8% accuracy but catch zero frauds.\n",
                "\n",
                "**Goal:** Build a model that maximizes **Recall** (catching as many frauds as possible) while maintaining acceptable **Precision** (minimizing false alarms). We will use **Interactive Visualizations** to explore this imbalance deeply."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1ï¸âƒ£ Importing Libraries ğŸ“¦"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Core Libraries\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import warnings\n",
                "\n",
                "# Interactive Visualization\n",
                "import plotly.express as px\n",
                "import plotly.graph_objects as go\n",
                "import plotly.figure_factory as ff\n",
                "from plotly.subplots import make_subplots\n",
                "\n",
                "# Interactive Widgets\n",
                "from ipywidgets import interact, widgets\n",
                "\n",
                "# Modeling & Preprocessing\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import (\n",
                "    classification_report, confusion_matrix,\n",
                "    accuracy_score, precision_score, recall_score, f1_score,\n",
                "    roc_auc_score, roc_curve, precision_recall_curve\n",
                ")\n",
                "from imblearn.over_sampling import SMOTE\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "print('âœ… All libraries loaded with Interactive Capabilities! ğŸš€')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2ï¸âƒ£ Data Loading & Exploration ğŸ“‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv('creditcard.csv')\n",
                "print(f'ğŸ“ Shape: {df.shape}')\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3ï¸âƒ£ Interactive EDA ğŸ”"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€ 3.1 Interactive Class Distribution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "\n",
                "counts = df['Class'].value_counts().reset_index()\n",
                "counts.columns = ['Class', 'Count']\n",
                "counts['Label'] = counts['Class'].map({0: 'Genuine ğŸŸ¢', 1: 'Fraud ğŸ”´'})\n",
                "\n",
                "fig = px.pie(counts, values='Count', names='Label', \n",
                "             title='ğŸ“Š Class Imbalance Distribution',\n",
                "             color='Label',\n",
                "             color_discrete_map={'Genuine ğŸŸ¢': '#00CC96', 'Fraud ğŸ”´': '#EF553B'},\n",
                "             hole=0.4)\n",
                "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**ğŸ’¡ Interpretation:** The dataset is **extremely imbalanced** (only ~0.17% fraud). Interactive charts help visualize this huge disparity clearly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€ 3.2 Feature Distribution Explorer (Interactive Widget) â”€â”€â”€â”€\n",
                "\n",
                "print(\"ğŸ‘‡ Explore distributions of different V-features by Class\")\n",
                "@interact(Feature=['V1', 'V2', 'V3', 'V4', 'V5', 'V10', 'V14', 'Amount'])\n",
                "def plot_feature_dist(Feature):\n",
                "    fig = px.histogram(df, x=Feature, color='Class',\n",
                "                       nbins=50,\n",
                "                       title=f'Distribution of {Feature} by Class',\n",
                "                       barmode='overlay',\n",
                "                       opacity=0.7,\n",
                "                       color_discrete_map={0: '#00CC96', 1: '#EF553B'},\n",
                "                       labels={'Class': 'Transaction Type'})\n",
                "    fig.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€ 3.3 Transaction Amount vs Time (Interactive) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "\n",
                "fig = px.scatter(df.sample(2000), x='Time', y='Amount', color='Class',\n",
                "                 title='â±ï¸ Transaction Amount vs. Time (Sampled)',\n",
                "                 color_continuous_scale=['#00CC96', '#EF553B'],\n",
                "                 size='Amount', size_max=20,\n",
                "                 hover_data=['V1', 'V2'])\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€ 3.4 Interactive Correlation Heatmap â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "\n",
                "corr = df.corr()\n",
                "\n",
                "fig = px.imshow(corr, text_auto=False, aspect=\"auto\",\n",
                "                title='ğŸ”¥ Feature Correlation Matrix',\n",
                "                color_continuous_scale='RdBu_r',\n",
                "                origin='lower')\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4ï¸âƒ£ Data Preprocessing ğŸ§¹\n",
                "\n",
                "We need to scale the `Amount` and `Time` columns as other `V` features are already scaled."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scaler = StandardScaler()\n",
                "df['Amount_Scaled'] = scaler.fit_transform(df['Amount'].values.reshape(-1, 1))\n",
                "df['Time_Scaled'] = scaler.fit_transform(df['Time'].values.reshape(-1, 1))\n",
                "\n",
                "df.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
                "\n",
                "X = df.drop('Class', axis=1)\n",
                "y = df['Class']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "print('âœ… Data Scaled & Split Successfully!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5ï¸âƒ£ Handling Imbalance (SMOTE) âš–ï¸"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('â³ Applying SMOTE... (This might act slow mostly because resizing huge datasets)')\n",
                "smote = SMOTE(random_state=42)\n",
                "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
                "\n",
                "print(f'âœ… Resampled Shape: {X_train_resampled.shape}')\n",
                "print(f'âœ… Genuine count: {sum(y_train_resampled == 0)}')\n",
                "print(f'âœ… Fraud count:   {sum(y_train_resampled == 1)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6ï¸âƒ£ Model Training & Evaluation ğŸ¤–"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = LogisticRegression(max_iter=1000)\n",
                "model.fit(X_train_resampled, y_train_resampled)\n",
                "\n",
                "y_pred = model.predict(X_test)\n",
                "\n",
                "print('âœ… Model Trained!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# â”€â”€ 6.1 Interactive Confusion Matrix â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "\n",
                "# Create annotated heatmap\n",
                "fig = ff.create_annotated_heatmap(z=cm, x=['Predicted Genuine', 'Predicted Fraud'], \n",
                "                                  y=['Actual Genuine', 'Actual Fraud'], \n",
                "                                  colorscale='Blues', showscale=True)\n",
                "\n",
                "fig.update_layout(title_text='ğŸ“‰ Confusion Matrix')\n",
                "fig.show()\n",
                "\n",
                "print('\\nğŸ“„ Classification Report:\\n')\n",
                "print(classification_report(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ğŸ‰ Conclusion\n",
                "We successfully:\n",
                "1. Explored the data using **Interactive Plots**.\n",
                "2. Handled class imbalance using **SMOTE**.\n",
                "3. Trained a Logistic Regression model.\n",
                "4. Visualized results with an **Interactive Confusion Matrix**."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}