{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Titanic Survival Prediction\n",
                "\n",
                "**Author:** Piyush Ramteke  \n",
                "**Program:** CodSoft Data Science Internship  \n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Problem Statement\n",
                "\n",
                "The sinking of the Titanic in 1912 is one of the deadliest maritime disasters in history. Out of 2,224 passengers and crew, more than 1,500 lost their lives.\n",
                "\n",
                "**Objective:** Build a Machine Learning model to predict whether a passenger **survived or not** based on features like age, gender, ticket class, fare, and family size.\n",
                "\n",
                "This is a **binary classification** problem:\n",
                "- **0** → Did not survive\n",
                "- **1** → Survived"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Import Libraries & Load Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── Import Libraries ─────────────────────────────────────────\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import warnings\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score, confusion_matrix, classification_report,\n",
                "    precision_score, recall_score, f1_score\n",
                ")\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "sns.set_style('whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "plt.rcParams['font.size'] = 12\n",
                "\n",
                "print('All libraries loaded.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── Load Dataset ─────────────────────────────────────────────\n",
                "\n",
                "df = pd.read_csv('Titanic-Dataset.csv')\n",
                "\n",
                "print(f'Dataset Shape: {df.shape[0]} rows × {df.shape[1]} columns')\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Column Descriptions:**\n",
                "\n",
                "| Feature | Description |\n",
                "|---------|-------------|\n",
                "| `PassengerId` | Unique ID for each passenger |\n",
                "| `Survived` | **Target** — 0 = No, 1 = Yes |\n",
                "| `Pclass` | Ticket class — 1 = 1st, 2 = 2nd, 3 = 3rd |\n",
                "| `Name` | Passenger name |\n",
                "| `Sex` | Gender |\n",
                "| `Age` | Age in years |\n",
                "| `SibSp` | Number of siblings/spouses aboard |\n",
                "| `Parch` | Number of parents/children aboard |\n",
                "| `Ticket` | Ticket number |\n",
                "| `Fare` | Ticket fare |\n",
                "| `Cabin` | Cabin number |\n",
                "| `Embarked` | Port of embarkation — C = Cherbourg, Q = Queenstown, S = Southampton |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 3. Exploratory Data Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 3.1 Dataset Info ─────────────────────────────────────────\n",
                "\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 3.2 Missing Values Summary ──────────────────────────────\n",
                "\n",
                "missing = df.isnull().sum()\n",
                "missing_pct = (missing / len(df) * 100).round(2)\n",
                "\n",
                "missing_df = pd.DataFrame({\n",
                "    'Missing Count': missing,\n",
                "    'Percentage (%)': missing_pct\n",
                "}).sort_values('Missing Count', ascending=False)\n",
                "\n",
                "print('Missing Values Summary:')\n",
                "print('=' * 40)\n",
                "missing_df[missing_df['Missing Count'] > 0]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Observations:**\n",
                "- **Cabin** — 77% missing → too many gaps, we'll drop it\n",
                "- **Age** — 19.9% missing → we'll fill with the median age\n",
                "- **Embarked** — only 2 missing → we'll fill with the most common port"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 3.3 Survival Distribution ───────────────────────────────\n",
                "\n",
                "surv_counts = df['Survived'].value_counts()\n",
                "surv_pct = df['Survived'].value_counts(normalize=True) * 100\n",
                "\n",
                "print('Survival Distribution:')\n",
                "print(f'  Did Not Survive (0): {surv_counts[0]}  ({surv_pct[0]:.1f}%)')\n",
                "print(f'  Survived        (1): {surv_counts[1]}  ({surv_pct[1]:.1f}%)')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 3.4 Visualize Survival Distribution ─────────────────────\n",
                "\n",
                "colors = ['#e74c3c', '#2ecc71']\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
                "\n",
                "# Bar chart\n",
                "bars = axes[0].bar(['Did Not Survive (0)', 'Survived (1)'],\n",
                "                   surv_counts.values, color=colors, edgecolor='black')\n",
                "axes[0].set_title('Survival Count', fontsize=15, fontweight='bold')\n",
                "axes[0].set_ylabel('Count')\n",
                "for b, c in zip(bars, surv_counts.values):\n",
                "    axes[0].text(b.get_x()+b.get_width()/2, b.get_height()+5,\n",
                "                str(c), ha='center', fontweight='bold', fontsize=13)\n",
                "\n",
                "# Pie chart\n",
                "axes[1].pie(surv_counts, labels=['Did Not Survive', 'Survived'],\n",
                "            autopct='%1.1f%%', colors=colors, explode=(0.02, 0.05),\n",
                "            shadow=True, textprops={'fontsize': 13})\n",
                "axes[1].set_title('Survival Proportion', fontsize=15, fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 3.5 Survival by Gender ──────────────────────────────────\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
                "\n",
                "sns.countplot(x='Sex', hue='Survived', data=df, palette=colors, \n",
                "              edgecolor='black', ax=axes[0])\n",
                "axes[0].set_title('Survival by Gender', fontsize=15, fontweight='bold')\n",
                "axes[0].legend(['No', 'Yes'], title='Survived')\n",
                "\n",
                "# Survival by Pclass\n",
                "sns.countplot(x='Pclass', hue='Survived', data=df, palette=colors,\n",
                "              edgecolor='black', ax=axes[1])\n",
                "axes[1].set_title('Survival by Ticket Class', fontsize=15, fontweight='bold')\n",
                "axes[1].legend(['No', 'Yes'], title='Survived')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f'Female survival rate: {df[df[\"Sex\"]==\"female\"][\"Survived\"].mean()*100:.1f}%')\n",
                "print(f'Male survival rate:   {df[df[\"Sex\"]==\"male\"][\"Survived\"].mean()*100:.1f}%')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 3.6 Age Distribution by Survival ────────────────────────\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(10, 5))\n",
                "\n",
                "ax.hist(df[df['Survived']==0]['Age'].dropna(), bins=30, alpha=0.7,\n",
                "        color=colors[0], label='Did Not Survive', edgecolor='black')\n",
                "ax.hist(df[df['Survived']==1]['Age'].dropna(), bins=30, alpha=0.7,\n",
                "        color=colors[1], label='Survived', edgecolor='black')\n",
                "ax.set_title('Age Distribution by Survival', fontsize=15, fontweight='bold')\n",
                "ax.set_xlabel('Age')\n",
                "ax.set_ylabel('Count')\n",
                "ax.legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Key EDA Findings:**\n",
                "- ~61.6% of passengers **did not survive** — moderately imbalanced\n",
                "- **Females** had a much higher survival rate (~74%) than males (~19%) — \"women and children first\"\n",
                "- **1st class** passengers survived more often than 3rd class\n",
                "- **Young children** (age < 5) had better survival chances\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Data Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 4.1 Handle Missing Values ───────────────────────────────\n",
                "\n",
                "# Age → fill with median (robust to outliers)\n",
                "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
                "\n",
                "# Embarked → fill with mode (most common port)\n",
                "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
                "\n",
                "# Cabin → drop (77% missing, not useful)\n",
                "df.drop('Cabin', axis=1, inplace=True)\n",
                "\n",
                "print('Missing values after handling:')\n",
                "print(df.isnull().sum()[df.isnull().sum() > 0])\n",
                "if df.isnull().sum().sum() == 0:\n",
                "    print('→ No missing values remaining.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**What we did:**\n",
                "- **Age:** Filled with median (28.0) — better than mean because it's not affected by extreme ages\n",
                "- **Embarked:** Filled with \"S\" (Southampton) — the most common embarkation port\n",
                "- **Cabin:** Dropped entirely — 77% of values are missing, making it unreliable"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 4.2 Drop Unnecessary Columns ────────────────────────────\n",
                "# Name, Ticket, PassengerId don't help prediction.\n",
                "\n",
                "df.drop(['Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)\n",
                "\n",
                "print(f'Columns after dropping: {list(df.columns)}')\n",
                "print(f'Shape: {df.shape}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 4.3 Create New Feature: FamilySize ─────────────────────\n",
                "# Combine SibSp + Parch to see total family members aboard.\n",
                "\n",
                "df['FamilySize'] = df['SibSp'] + df['Parch']\n",
                "\n",
                "print('FamilySize feature created (SibSp + Parch)')\n",
                "print(f'\\nFamilySize distribution:')\n",
                "print(df['FamilySize'].value_counts().sort_index())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── Visualize FamilySize vs Survival ────────────────────────\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(10, 5))\n",
                "sns.countplot(x='FamilySize', hue='Survived', data=df,\n",
                "              palette=colors, edgecolor='black', ax=ax)\n",
                "ax.set_title('Survival by Family Size', fontsize=15, fontweight='bold')\n",
                "ax.legend(['No', 'Yes'], title='Survived')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print('Passengers traveling alone (FamilySize=0) had lower survival rates.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 4.4 Encode Categorical Features ────────────────────────\n",
                "# Sex → 0 (male), 1 (female)\n",
                "# Embarked → 0 (C), 1 (Q), 2 (S)\n",
                "\n",
                "le = LabelEncoder()\n",
                "\n",
                "df['Sex'] = le.fit_transform(df['Sex'])           # female=0, male=1\n",
                "df['Embarked'] = le.fit_transform(df['Embarked']) # C=0, Q=1, S=2\n",
                "\n",
                "print('Categorical encoding applied:')\n",
                "print(f'  Sex      → {dict(zip([\"female\",\"male\"], [0,1]))}')\n",
                "print(f'  Embarked → {dict(zip([\"C\",\"Q\",\"S\"], [0,1,2]))}')\n",
                "print(f'\\nFinal columns: {list(df.columns)}')\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Preprocessing Summary:**\n",
                "- ✅ Missing values handled (Age → median, Embarked → mode, Cabin → dropped)\n",
                "- ✅ Unnecessary columns dropped (Name, Ticket, PassengerId)\n",
                "- ✅ New feature created: `FamilySize = SibSp + Parch`\n",
                "- ✅ Categorical features encoded to numbers (Sex, Embarked)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Train/Test Split & Feature Scaling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 5.1 Separate Features and Target ────────────────────────\n",
                "\n",
                "X = df.drop('Survived', axis=1)\n",
                "y = df['Survived']\n",
                "\n",
                "print(f'Features: {list(X.columns)}')\n",
                "print(f'Target: Survived')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 5.2 Train/Test Split (80-20) ────────────────────────────\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "print(f'Training set: {X_train.shape[0]} samples')\n",
                "print(f'Testing set:  {X_test.shape[0]} samples')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 5.3 Feature Scaling ──────────────────────────────────────\n",
                "# Logistic Regression is sensitive to feature scale.\n",
                "# StandardScaler makes all features have mean=0, std=1.\n",
                "\n",
                "scaler = StandardScaler()\n",
                "\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled  = scaler.transform(X_test)  # use same scaling as training!\n",
                "\n",
                "print('Feature scaling applied (StandardScaler).')\n",
                "print('Note: fit_transform on train, transform only on test — prevents data leakage.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 6. Model Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 6.1 Logistic Regression ─────────────────────────────────\n",
                "# Simple, fast, and interpretable baseline classifier.\n",
                "\n",
                "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
                "lr.fit(X_train_scaled, y_train)\n",
                "\n",
                "lr_pred = lr.predict(X_test_scaled)\n",
                "\n",
                "print('Logistic Regression — trained.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 6.2 Random Forest Classifier ────────────────────────────\n",
                "# Ensemble method — combines 100 decision trees for better accuracy.\n",
                "# Random Forest doesn't require feature scaling, but we use\n",
                "# the scaled data for consistency.\n",
                "\n",
                "rf = RandomForestClassifier(\n",
                "    n_estimators=100,\n",
                "    max_depth=10,\n",
                "    random_state=42,\n",
                "    n_jobs=-1\n",
                ")\n",
                "rf.fit(X_train_scaled, y_train)\n",
                "\n",
                "rf_pred = rf.predict(X_test_scaled)\n",
                "\n",
                "print('Random Forest — trained.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Both models trained on **scaled features** and predictions made on the **test set**.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Model Evaluation\n",
                "\n",
                "We evaluate using five metrics:\n",
                "\n",
                "| Metric | What it tells us |\n",
                "|--------|------------------|\n",
                "| **Accuracy** | Overall % of correct predictions |\n",
                "| **Precision** | Of those predicted as survived, how many actually survived? |\n",
                "| **Recall** | Of those who actually survived, how many did we predict correctly? |\n",
                "| **F1-Score** | Balance between Precision and Recall |\n",
                "| **Confusion Matrix** | Visual breakdown of correct vs incorrect predictions |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 7.1 Evaluation Helper Function ──────────────────────────\n",
                "\n",
                "def evaluate_model(name, y_true, y_pred):\n",
                "    \"\"\"Print all evaluation metrics for a model.\"\"\"\n",
                "    acc  = accuracy_score(y_true, y_pred)\n",
                "    prec = precision_score(y_true, y_pred)\n",
                "    rec  = recall_score(y_true, y_pred)\n",
                "    f1   = f1_score(y_true, y_pred)\n",
                "    \n",
                "    print(f'\\n{\"=\" * 50}')\n",
                "    print(f'{name}')\n",
                "    print(f'{\"=\" * 50}')\n",
                "    print(f'  Accuracy:  {acc:.4f}  ({acc*100:.2f}%)')\n",
                "    print(f'  Precision: {prec:.4f}')\n",
                "    print(f'  Recall:    {rec:.4f}')\n",
                "    print(f'  F1-Score:  {f1:.4f}')\n",
                "    \n",
                "    return {'Accuracy': acc, 'Precision': prec, 'Recall': rec, 'F1-Score': f1}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 7.2 Evaluate Both Models ────────────────────────────────\n",
                "\n",
                "lr_metrics = evaluate_model('Logistic Regression', y_test, lr_pred)\n",
                "rf_metrics = evaluate_model('Random Forest', y_test, rf_pred)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 7.3 Confusion Matrices ──────────────────────────────────\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
                "\n",
                "for ax, name, pred in [\n",
                "    (axes[0], 'Logistic Regression', lr_pred),\n",
                "    (axes[1], 'Random Forest', rf_pred)\n",
                "]:\n",
                "    cm = confusion_matrix(y_test, pred)\n",
                "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
                "                xticklabels=['Not Survived','Survived'],\n",
                "                yticklabels=['Not Survived','Survived'],\n",
                "                annot_kws={'fontsize': 14})\n",
                "    ax.set_title(name, fontsize=14, fontweight='bold')\n",
                "    ax.set_ylabel('Actual')\n",
                "    ax.set_xlabel('Predicted')\n",
                "\n",
                "plt.suptitle('Confusion Matrices', fontsize=17, fontweight='bold', y=1.02)\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print('Reading guide:')\n",
                "print('  Top-left  = Correctly predicted NOT survived')\n",
                "print('  Top-right = Wrongly predicted survived (False Positive)')\n",
                "print('  Bot-left  = Wrongly predicted not survived (False Negative)')\n",
                "print('  Bot-right = Correctly predicted survived')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 7.4 Classification Reports ──────────────────────────────\n",
                "\n",
                "print('=' * 55)\n",
                "print('Logistic Regression — Classification Report')\n",
                "print('=' * 55)\n",
                "print(classification_report(y_test, lr_pred,\n",
                "                            target_names=['Not Survived', 'Survived']))\n",
                "\n",
                "print('=' * 55)\n",
                "print('Random Forest — Classification Report')\n",
                "print('=' * 55)\n",
                "print(classification_report(y_test, rf_pred,\n",
                "                            target_names=['Not Survived', 'Survived']))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 8. Model Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 8.1 Comparison Table ────────────────────────────────────\n",
                "\n",
                "comparison = pd.DataFrame({\n",
                "    'Logistic Regression': lr_metrics,\n",
                "    'Random Forest': rf_metrics\n",
                "}).round(4)\n",
                "\n",
                "print('Final Model Comparison:')\n",
                "print('=' * 55)\n",
                "comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 8.2 Visual Comparison ───────────────────────────────────\n",
                "\n",
                "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
                "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
                "\n",
                "model_colors = ['#2980b9', '#c0392b']\n",
                "\n",
                "for i, m in enumerate(metrics):\n",
                "    ax = axes[i]\n",
                "    vals = [lr_metrics[m], rf_metrics[m]]\n",
                "    bars = ax.bar(['Logistic\\nRegression', 'Random\\nForest'],\n",
                "                 vals, color=model_colors, edgecolor='black')\n",
                "    ax.set_title(m, fontsize=14, fontweight='bold')\n",
                "    ax.set_ylim(0, 1.15)\n",
                "    for b, v in zip(bars, vals):\n",
                "        ax.text(b.get_x()+b.get_width()/2, b.get_height()+0.02,\n",
                "                f'{v:.4f}', ha='center', fontweight='bold', fontsize=12)\n",
                "\n",
                "plt.suptitle('Model Performance Comparison',\n",
                "             fontsize=18, fontweight='bold', y=1.04)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 8.3 Feature Importance (Random Forest) ──────────────────\n",
                "\n",
                "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
                "importances = importances.sort_values(ascending=True)\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(10, 6))\n",
                "importances.plot(kind='barh', color='#2980b9', edgecolor='black', ax=ax)\n",
                "ax.set_title('Feature Importance (Random Forest)', fontsize=15, fontweight='bold')\n",
                "ax.set_xlabel('Importance')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f'\\nTop 3 most important features:')\n",
                "for feat, imp in importances.tail(3)[::-1].items():\n",
                "    print(f'  {feat}: {imp:.4f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── 8.4 Best Model Selection ────────────────────────────────\n",
                "\n",
                "best = 'Random Forest' if rf_metrics['Accuracy'] >= lr_metrics['Accuracy'] else 'Logistic Regression'\n",
                "best_metrics = rf_metrics if best == 'Random Forest' else lr_metrics\n",
                "\n",
                "print('Best Model:', best)\n",
                "print(f'  Accuracy:  {best_metrics[\"Accuracy\"]:.4f}')\n",
                "print(f'  Precision: {best_metrics[\"Precision\"]:.4f}')\n",
                "print(f'  Recall:    {best_metrics[\"Recall\"]:.4f}')\n",
                "print(f'  F1-Score:  {best_metrics[\"F1-Score\"]:.4f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 9. Conclusion\n",
                "\n",
                "### Key Findings\n",
                "\n",
                "1. **Data Exploration:** The Titanic dataset has 891 passengers with 12 features. About 61.6% did not survive. Key survival factors: gender (females had 74% survival rate vs males at 19%), ticket class, and age.\n",
                "\n",
                "2. **Preprocessing:** We handled missing values (Age → median, Embarked → mode, Cabin → dropped), encoded categorical variables, and created a new `FamilySize` feature.\n",
                "\n",
                "3. **Models:** Both Logistic Regression and Random Forest were trained and evaluated.\n",
                "\n",
                "4. **Results:** Random Forest generally has an edge due to its ability to capture non-linear relationships and feature interactions. Logistic Regression performs well as a baseline.\n",
                "\n",
                "5. **Feature Importance:** `Sex`, `Fare`, and `Age` tend to be the most important features for predicting survival — consistent with the historical \"women and children first\" policy.\n",
                "\n",
                "### What We Learned\n",
                "\n",
                "- Always explore and visualize data before building models\n",
                "- Handle missing values thoughtfully — median for numerical, mode for categorical\n",
                "- Feature engineering (like `FamilySize`) can provide additional predictive power\n",
                "- Compare multiple models to find the best performer\n",
                "- Feature scaling matters for distance-based algorithms like Logistic Regression\n",
                "\n",
                "---\n",
                "\n",
                "*Project by **Piyush Ramteke** — CodSoft Data Science Internship*"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}